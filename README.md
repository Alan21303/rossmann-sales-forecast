# ğŸ“Š Rossmann Sales Forecasting

Forecasting daily sales for Rossmann stores using **Machine Learning**.
This repo contains the **end-to-end pipeline** â†’ data processing, model training, evaluation, and deployment via **Streamlit**.

![Project Workflow](img/image1.png)

---

## ğŸ—‚ï¸ Repository Structure

```
rossmann_sales_project/
â”‚
â”œâ”€â”€ app.py                  # Streamlit dashboard for visualization
â”œâ”€â”€ src/                    # Training & utility scripts
â”‚   â”œâ”€â”€ data_preprocessing.py   # Cleans & prepares dataset
â”‚   â”œâ”€â”€ train_random_forest.py  # Trains Random Forest model
â”‚   â”œâ”€â”€ train_xgboost.py        # Trains standard XGBoost model
â”‚   â”œâ”€â”€ train_xgb_bayes.py      # Trains XGBoost with Bayesian optimization
â”‚   â”œâ”€â”€ train_ensemble.py       # Trains ensemble models (XGB+RF, XGB+LGBM+RF)
â”‚   â”œâ”€â”€ utils.py                # Helper functions (metrics, save/load models)
â”‚   â””â”€â”€ evaluate.py             # Evaluate models & generate results table
â”‚
â”œâ”€â”€ models/                 # Saved models (.pkl)
â”œâ”€â”€ data/                   # Raw & processed datasets
â”œâ”€â”€ notebooks/              # EDA & experiments
â”œâ”€â”€ outputs/                # Logs, validation metrics, plots
â”œâ”€â”€ img/                    # Screenshots for README
â”œâ”€â”€ requirements.txt        # Dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## ğŸ§  Training Scripts in `/src/`

Each training file builds & saves a model in `/models/`.

| Script                   | Purpose                                                                                         | Output                               |
| ------------------------ | ----------------------------------------------------------------------------------------------- | ------------------------------------ |
| `data_preprocessing.py`  | Cleans raw data, handles missing values, encodes categorical features, saves processed dataset. | `data/processed_train.csv`           |
| `train_random_forest.py` | Trains Random Forest model. Good baseline but very large file size (17GB).                      | `models/random_forest.pkl`           |
| `train_xgboost.py`       | Trains standard XGBoost. Best performer with stable validation metrics.                         | `models/xgboost.pkl`                 |
| `train_xgb_bayes.py`     | Runs Bayesian Optimization for XGBoost hyperparams. Validation unstable.                        | `models/xgboost_bayes.pkl`           |
| `train_ensemble.py`      | Trains ensemble models (XGB+RF, XGB+LGBM+RF). Only marginal improvements.                       | `models/ensemble.pkl`                |
| `evaluate.py`            | Loads models, calculates metrics (RMSE, RMSPE), and prints summary.                             | Results table (saved in `/outputs/`) |
| `utils.py`               | Helper functions for metrics, plots, saving/loading pickle files.                               | Utility methods                      |

---

## ğŸ“¸ Streamlit App Preview

| Dashboard View                  | Forecast Visualization           | Results Table                        |
| ------------------------------- | -------------------------------- | ------------------------------------ |
| ![App Controls](img/image1.png) | ![Forecast Plot](img/image2.png) | ![Predictions Table](img/image3.png) |

---

## ğŸ“Š Model Performance Summary

| Model                      | Train RMSE | Valid RMSE | Valid RMSPE | Notes                                |
| -------------------------- | ---------- | ---------- | ----------- | ------------------------------------ |
| Random Forest              | \~207      | \~560      | \~0.0831    | Overfits, 17+ GB model file.         |
| XGBoost (Standard)         | \~419      | \~460      | \~0.0720    | âœ… Best performer. Small model size. |
| XGBoost (Bayes Opt)        | \~648      | \~649      | inf         | Unstable, bad search space.          |
| Ensemble (XGB + RF)        | \~459      | \~589      | inf         | Worse than plain XGBoost.            |
| Ensemble (XGB + LGBM + RF) | 430â€“450    | 470â€“520    | 0.073â€“0.078 | Stable, but only marginally better.  |

---

## âš¡ Running the Project

### 1ï¸âƒ£ Clone repo

```bash
git clone https://github.com/Alan21303/rossmann-sales-forecast.git
cd rossmann-sales-forecast
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Train models

Run individual training scripts:

```bash
python src/train_random_forest.py
python src/train_xgboost.py
python src/train_xgb_bayes.py
python src/train_ensemble.py
```

Models will be saved in `/models/`.

### 4ï¸âƒ£ Evaluate models

```bash
python src/evaluate.py
```

This generates performance metrics in `/outputs/`.

### 5ï¸âƒ£ Launch Streamlit app

```bash
streamlit run app.py
```

App will be available at ğŸ‘‰ `http://localhost:8501`

---

## âœ¨ What We Achieved

âœ”ï¸ Built a **full ML pipeline** (data â†’ model â†’ dashboard).
âœ”ï¸ Compared multiple models (RF, XGB, Ensembles).
âœ”ï¸ Identified **XGBoost** as the best model.
âœ”ï¸ Deployed results via **Streamlit dashboard**.

---
